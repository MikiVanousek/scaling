_wandb:
    value:
        cli_version: 0.21.1
        e:
            p2ga7ze0a4cwl582jndljnp0zsk1manx:
                args:
                    - --config
                    - cfgs/real_smallest.yaml
                codePath: train.py
                codePathLocal: train.py
                cpu_count: 6
                cpu_count_logical: 12
                disk:
                    /:
                        total: "73391005696"
                        used: "57191108608"
                email: vanousekmikulas@gmail.com
                executable: /home/miki/epfl/scaling/.pixi/envs/default/bin/python
                git:
                    commit: 511e841d7078ce391bffd7ae2ec3cda38936e21c
                    remote: git@github.com:MikiVanousek/scaling.git
                host: fedora
                memory:
                    total: "32331980800"
                os: Linux-6.15.10-200.fc42.x86_64-x86_64-with-glibc2.41
                program: /home/miki/epfl/scaling/train.py
                python: CPython 3.13.7
                root: /home/miki/epfl/scaling
                startedAt: "2025-09-22T16:04:59.422447Z"
                writerId: p2ga7ze0a4cwl582jndljnp0zsk1manx
        m: []
        python_version: 3.13.7
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
            "2":
                - 1
                - 11
                - 49
                - 51
            "3":
                - 2
                - 16
            "4": 3.13.7
            "5": 0.21.1
            "6": 4.56.2
            "12": 0.21.1
            "13": linux-x86_64
batch_size:
    value: 32
dataset:
    value: MikiV/SimpleStories-SimpleStories-chunked-128
eval_interval:
    value: 100
gradient_accumulation_steps:
    value: 1
learning_rate:
    value: "1e-3"
lr_warmup_steps:
    value: 1000
model_shape:
    value:
        d_model: 256
        d_vocab: 4096
        layers: 6
        n_heads: 4
samples:
    value: 1000
seq_len:
    value: 128
weight_decay:
    value: 0.01
